{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6afd105c",
   "metadata": {},
   "source": [
    "# Writeup Behavioural Clonning project\n",
    "\n",
    "\n",
    "## The goals / steps of this project are the following:\n",
    "\n",
    "* Use the simulator to collect data of good driving behavior\n",
    "* Build, a convolution neural network in Keras that predicts steering angles from images\n",
    "* Train and validate the model with a training and validation set\n",
    "* Test that the model successfully drives around track one without leaving the road\n",
    "* Summarize the results with a written report\n",
    "\n",
    "## Model architecture and  Training strategy\n",
    "\n",
    "The model that I decided to use was a modified LeNet, because I think this model is appropiate because this neural network has to learn some patterns in an image, and as we have seen previously this kind of model respond really good when it comes to learning 2d patterns in an image. So the intuition behind it would be to use some CNN to find the patterns in the road, then learn it and to identify the kind of turn in the road, then finally give an accetable angle output.\n",
    "\n",
    "* layer1: A lamda layer to homogenize pixel data from 255-0 to 1-0.\n",
    "* layer2: Cropping layer from keras to crop the sky and trees as well as the very bottom of the floor.\n",
    "* layer3: Convolutional layer with 64 filters and kernel size of 3x3\n",
    "* layer4: An avergage pooling layer\n",
    "* layer5: Convolutional layer with 32 filters and a kernel size of 3x3\n",
    "* layer6: An average pooling layer\n",
    "* layer7: Flatten the convolutinal layers\n",
    "* layer9: A neuronal network with 120 neurons\n",
    "* layer10: A .2 dropout\n",
    "* layer11: A neuronal network with 84 neurons\n",
    "* layer12: A .2 dropout\n",
    "* layer13: Output layer\n",
    "\n",
    "\n",
    "and here is a snipet of the code:\n",
    "\n",
    "```\n",
    "model.add(Lambda(lambda x: x/255,input_shape = (160,320,3)))\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(AveragePooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=120, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(units=84, activation='relu'))\n",
    "model.add(Dropout(.2))\n",
    "model.add(Dense(1))\n",
    "```\n",
    "\n",
    "\n",
    "## Training Data\n",
    "\n",
    "The training data used to train this model were four laps, which in total were 34,170 pictures. I tried to drive the car as clean as I can, using the mouse. By using the mouse instead of the keyboard makes more soft the angle of the every turn. To use a mouse or even better a gamming racing wheel, by using this device will deliver a more precise and softer angle that will produce beter results in the output model. I don't own this device so I did my best to produce a continous mouse angle in each turn.\n",
    "\n",
    "The intermitent/data given those jumps looks like the following data:\n",
    "\n",
    "|angle|\n",
    "|------|\n",
    "|-0.1584516|\n",
    "|-0.1584516|\n",
    "|-0.1313311|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|0|\n",
    "|-0.01915068|\n",
    "|-0.02872602|\n",
    "|-0.02872602|\n",
    "|-0.02872602|\n",
    "|-0.03590806|\n",
    "\n",
    "And what we are teaching is that in sharp curves its fine to go streight, which might not help much in training our model. And this of course result in a ambiguity for training phase and might confuse what to do when its given a turn. For that reason I decided a way to soften this sort of intermitent data.\n",
    "\n",
    "To get better results in the output and avoid that intermitent jumps in some sharps turns I decided to implement a filter that will help to soften that intermitent data from the use of the mouse. The filter used was a first order low-pass filter. with the following formula:\n",
    "\n",
    "xk =  alpha * x + (1 - alpha) * x k-1\n",
    "\n",
    "Acording to the previous statement I did my best to do some continous laps without getting away from the asphalt. In the end we did circa 5 laps that produce a really good results in the training.\n",
    "\n",
    "\n",
    "As mention in the sugestions of the Udacity Course I use the left and right video to increase the information of the dataset. Morover I decided to use +-.3 instead of +-.2 in the left/right camera gap.\n",
    "\n",
    "## PROCESS KILLED\n",
    "\n",
    "Due to the high amount of data, my computer couldn't stand the amount of data requied in RAM and the kernell output \"PROCES KILLED\" then I read that the problem was caused because when adding all the list with the information with the 34k+ pictures the tensors finish all my RAM. that's why I decided to implement a generator that could help me to process the data when needed.\n",
    "\n",
    "The generator was implemented with the following code:\n",
    "\n",
    "```\n",
    "def generator(samples,batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while 1:\n",
    "        #shuffle(samples)\n",
    "        for offset in range(0,num_samples,batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            measurements = []\n",
    "            previous = 0\n",
    "            alpha = .5\n",
    "            beta = 1 - alpha\n",
    "            filtered = 0\n",
    "            for line in batch_samples:\n",
    "                for source_path in line[0:3]:\n",
    "                    filtered = float(line[3])*alpha + previous*beta \n",
    "                    file_name = source_path.split('/')[-1]\n",
    "                    current_path = 'IMG/' + file_name\n",
    "                    image = cv2.imread(current_path)\n",
    "                    image_flipped = cv2.flip(image,1)\n",
    "                    images.append(image)\n",
    "                    if file_name.split('_')[0] == 'center':\n",
    "                        measurements.append(filtered)\n",
    "                        images.append(image_flipped)\n",
    "                        measurements.append(-1*filtered)\n",
    "                    elif file_name.split('_')[0] == 'left':\n",
    "                        measurements.append(filtered+.3)\n",
    "                        images.append(image_flipped)\n",
    "                        measurements.append(-1*filtered+.3)\n",
    "                    else:\n",
    "                        measurements.append(filtered-.3)\n",
    "                        images.append(image_flipped)\n",
    "                        measurements.append(-1*(filtered)-.3)\n",
    "                    previous = filtered\n",
    "\n",
    "            X_train = np.array(images)\n",
    "            Y_train = np.array(measurements)\n",
    "            yield sklearn.utils.shuffle(X_train, Y_train)\n",
    "```\n",
    "Generators are really helpful when we have huge data to train. This is another great tool to have when implementing the learning phase.\n",
    "\n",
    "\n",
    "## Personal Follow up\n",
    "This time I miss to convert from 3rgb channel to 1 grayscale channel. I think in this time gray scale would also work but with the bennefit of reducing the amount of time training and as well as reduce the size of the model.\n",
    "When looking the performance of the vehicle in the simulation, It seems as its turns are more sharp than its needed just like when we are learning to drive. I think that this is because 0.3 add up in the left and right camera is a bit high, we could lower this number to get a softer turn and get a better driving.\n",
    "\n",
    "\n",
    "## TAKE AWAYS\n",
    "Frankly speaking I am impressed with this project, Despite working with some models in deep learning in the past, I never tought that a CNN could \"copy\" my driving skils so easily. In my own opinion this project has been the most impresive of the projects, moreover this project has unlocked new perspectives of unthinkable capabilities of what deep learning can do.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf8c36",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2912e77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
